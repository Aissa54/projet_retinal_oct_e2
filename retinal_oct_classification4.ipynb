{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e13f3a",
   "metadata": {},
   "source": [
    "# Detecting Retina Damage From Optical Coherence Tomography (OCT) Images, using Transfer Learning on VGG16 CNN Model\n",
    "## Context\n",
    "Retinal Optical Coherence Tomography (OCT) is an imaging technique used to capture high-resolution cross sections of the retinas of living patients. Approximately 30 million OCT scans are performed each year, and the analysis and interpretation of these images takes up a significant amount of time (Swanson and Fujimoto, 2017).\n",
    "\n",
    "![Figure 1.](https://i.imgur.com/fSTeZMd.png)\n",
    "\n",
    "Figure 1. Representative Optical Coherence Tomography Images and the Workflow Diagram \\[Kermany et. al. 2018\\]\n",
    "\n",
    "(A) (Far left) Choroidal Neo-Vascularization (CNV) with neovascular membrane (white arrowheads) and associated subretinal fluid (arrows). (Middle left) Diabetic Macular Edema (DME) with retinal-thickening-associated intraretinal fluid (arrows). (Middle right) Multiple drusen (arrowheads) present in early AMD. (Far right) Normal retina with preserved foveal contour and absence of any retinal fluid/edema.\n",
    "\n",
    "## Content\n",
    "* The dataset is organized into 3 folders (train, test, val) and contains subfolders for each image category (NORMAL,CNV,DME,DRUSEN). There are 84,495 X-Ray images (JPEG) and 4 categories (NORMAL,CNV,DME,DRUSEN).\n",
    "* Images are labeled as (disease)-(randomized patient ID)-(image number by this patient) and split into 4 directories: CNV, DME, DRUSEN, and NORMAL.\n",
    "\n",
    "* Optical coherence tomography (OCT) images (Spectralis OCT, Heidelberg Engineering, Germany) were selected from retrospective cohorts of adult patients from the Shiley Eye Institute of the University of California San Diego, the California Retinal Research Foundation, Medical Center Ophthalmology Associates, the Shanghai First People’s Hospital, and Beijing Tongren Eye Center between July 1, 2013 and March 1, 2017.\n",
    "\n",
    "## Acknowledgements\n",
    "* Data: https://data.mendeley.com/datasets/rscbjbr9sj/2\n",
    "* Citation: http://www.cell.com/cell/fulltext/S0092-8674(18)30154-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6273548a",
   "metadata": {},
   "source": [
    "## Installing and Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dec5fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sn\n",
    "from skimage.transform import resize\n",
    "from skimage.color import gray2rgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from IPython.display import SVG\n",
    "import keract\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import applications, optimizers\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical, model_to_dot, plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca1d3c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eebfbbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 10:57:24.477084: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-14 10:57:24.995646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 37615 MB memory:  -> device: 0, name: A100-PCIE-40GB, pci bus id: 0000:81:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21699ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2453fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"OCT2017 /\"\n",
    "train_data_dir= 'OCT2017 /train/'\n",
    "val_data_dir= 'OCT2017 /val/'\n",
    "test_data_dir= 'OCT2017 /test/'\n",
    "img_width, img_height = 150, 150 \n",
    "channels = 3\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2d4e83",
   "metadata": {},
   "source": [
    "### Keras Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b3a5c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale= 1./255,\n",
    "    zoom_range= (0.73, 0.9),\n",
    "    horizontal_flip= True,\n",
    "    rotation_range= 10,\n",
    "    width_shift_range= 0.10,\n",
    "    fill_mode= 'constant',\n",
    "    height_shift_range= 0.10,   \n",
    "    brightness_range= (0.55, 0.9),\n",
    ")\n",
    "\n",
    "valid_test_datagen = ImageDataGenerator(\n",
    "    rescale= 1./255, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8086e1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 83484 images belonging to 4 classes.\n",
      "Found 32 images belonging to 4 classes.\n",
      "Found 968 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(  \n",
    "    train_data_dir,  \n",
    "    target_size= (img_width, img_height), \n",
    "    color_mode= 'rgb',\n",
    "    batch_size= batch_size,  \n",
    "    class_mode= 'categorical',\n",
    "    shuffle= True, \n",
    "    seed= 1337\n",
    ") \n",
    "\n",
    "valid_generator = valid_test_datagen.flow_from_directory(\n",
    "    val_data_dir,\n",
    "    target_size= (img_width, img_height),\n",
    "    color_mode= 'rgb',\n",
    "    batch_size= batch_size,  \n",
    "    class_mode= 'categorical',\n",
    "    shuffle= True, \n",
    "    seed= 1337\n",
    ")\n",
    "\n",
    "test_generator = valid_test_datagen.flow_from_directory(  \n",
    "    test_data_dir,  \n",
    "    target_size= (img_width, img_height), \n",
    "    color_mode= 'rgb',\n",
    "    batch_size= batch_size,        \n",
    "    class_mode= 'categorical',\n",
    "    shuffle= False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39386bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_generator.class_indices)  \n",
    "train_labels = train_generator.classes \n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "valid_labels = valid_generator.classes \n",
    "valid_labels = to_categorical(valid_labels, num_classes=num_classes)\n",
    "nb_train_samples = len(train_generator.filenames)  \n",
    "nb_valid_samples = len(valid_generator.filenames)\n",
    "nb_test_samples = len(test_generator.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e240ea3",
   "metadata": {},
   "source": [
    "# Model\n",
    "* VGG16 CNN architecture is used for calssification.\n",
    "* Pretrained on the 'ImageNet' dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae018c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16 = VGG16(include_top= False, input_shape= (img_width, img_height, channels), weights= 'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb745285",
   "metadata": {},
   "source": [
    "## Test numéro 4  amélioration du modèle de base : \n",
    "\n",
    "On rajoute couche dense au classifer avec une activation 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3646017b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               4194816   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,911,556\n",
      "Trainable params: 4,196,868\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "\n",
    "for layer in vgg16.layers:\n",
    "    model4.add(layer)\n",
    "\n",
    "for layer in model4.layers:\n",
    "    layer.trainable= False\n",
    "\n",
    "model4.add(Flatten(input_shape= (4, 4, 512)))\n",
    "model4.add(Dense(512, activation= 'relu'))\n",
    "model4.add(Dropout(0.15))\n",
    "model4.add(Dense(4,activation='softmax'))\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96fb6cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u000441/miniconda3/envs/simplon/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model4.compile(optimizer= keras.optimizers.Adam(lr= 0.0001), loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c82a5c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 10:57:57.740530: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2022-11-14 10:57:58.749067: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  11/2609 [..............................] - ETA: 47s - loss: 1.2182 - accuracy: 0.5511  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 10:57:59.241475: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2607/2609 [============================>.] - ETA: 0s - loss: 0.4983 - accuracy: 0.8172"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 10:59:19.183398: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at save_restore_v2_ops.cc:112 : PERMISSION_DENIED: /tmp/checkpoint_temp/part-00000-of-00001.data-00000-of-00001.tempstate432302510047275620; Permission denied\n"
     ]
    },
    {
     "ename": "PermissionDeniedError",
     "evalue": "{{function_node __wrapped__SaveV2_dtypes_44_device_/job:localhost/replica:0/task:0/device:CPU:0}} /tmp/checkpoint_temp/part-00000-of-00001.data-00000-of-00001.tempstate432302510047275620; Permission denied [Op:SaveV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m earlystop \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m callbacks_list \u001b[38;5;241m=\u001b[39m [earlystop,checkpoint]\n\u001b[0;32m---> 12\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel4\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                        \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/simplon/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/simplon/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m: {{function_node __wrapped__SaveV2_dtypes_44_device_/job:localhost/replica:0/task:0/device:CPU:0}} /tmp/checkpoint_temp/part-00000-of-00001.data-00000-of-00001.tempstate432302510047275620; Permission denied [Op:SaveV2]"
     ]
    }
   ],
   "source": [
    "numepochs = 15\n",
    "batch_size = 32\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
    "callbacks_list = [earlystop,checkpoint]\n",
    "history = model4.fit(train_generator,\n",
    "                        use_multiprocessing=True,\n",
    "                        workers=8,\n",
    "                        epochs=numepochs, \n",
    "                        batch_size = batch_size,\n",
    "                        validation_data=valid_generator, \n",
    "                        verbose=1,\n",
    "                        callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d0c4b2",
   "metadata": {},
   "source": [
    "### Evaluations on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a00ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "(eval_loss, eval_accuracy) = model4.evaluate(test_generator, batch_size= batch_size, verbose= 1)\n",
    "print('Test Loss: ', eval_loss)\n",
    "print('Test Accuracy: ', eval_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7ba0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot()\n",
    "plt.rcParams['figure.figsize'] = (6.0, 4.0)\n",
    "plt.title('Model4 Accuracy')\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training Accuracy','Validation Accuracy'])\n",
    "plt.savefig('Model4_acc_epoch.png', transparent= False, bbox_inches= 'tight', dpi= 400)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.subplot()\n",
    "plt.title('Model4 Loss')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training Loss','Validation Loss'])\n",
    "plt.savefig('Model4_loss_epoch.png', transparent= False, bbox_inches= 'tight', dpi= 400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5007e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model4.predict(test_generator, nb_test_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "cm = confusion_matrix(test_generator.classes, y_pred)\n",
    "df_cm = pd.DataFrame(cm, list(test_generator.class_indices.keys()), list(test_generator.class_indices.keys()))\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix Model4\\n')\n",
    "plt.savefig('confusion_matrix_model4.png', transparent= False, bbox_inches= 'tight', dpi= 400)\n",
    "plt.show()\n",
    "\n",
    "print('Classification Report Model4\\n')\n",
    "target_names = list(test_generator.class_indices.keys())\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d707d76",
   "metadata": {},
   "source": [
    "### Save the model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05302e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and architecture to single file\n",
    "model4.save(\"model4_retinal-oct.h5\")\n",
    "print(\"Saved model4 to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71150e21",
   "metadata": {},
   "source": [
    "### Prediction test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5309556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "model = tf.keras.models.load_model('retinal-oct.h5')\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "from keras.preprocessing import image\n",
    "\n",
    "test_image = tf.keras.utils.load_img(\"OCT2017 /test/CNV/CNV-1016042-1.jpeg\", target_size = (150, 150)) \n",
    "test_image = tf.keras.utils.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "#predict the result\n",
    "result = np.argmax(model.predict(test_image))\n",
    "print(result)\n",
    "print(list(train_generator.class_indices.keys())[list(train_generator.class_indices.values()).index(result)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
